<p align="center">
  <a href="https://discord.gg/RbeQMu886J">Join the community</a> •
  <a href="https://github.com/nebuly-ai/learning-AI-optimization#contribute">Contribute to the library</a>
</p>


<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/171454644-d4b980bc-15ab-4a31-847c-75c36c5bd96b.png">


# Resources

Awesome resource collection on quantization techniques.

- <a href="#literature-reviews">Literature reviews</a> and <a href="#papers">papers</a>
- <a href="#courses-webinars-and-blogs">Courses, webinars and blogs</a>

If you still didn't, check [Overview page on knowledge distillation](https://github.com/nebuly-ai/exploring-AI-optimization/blob/main/knowledge_distillation_overview.md) or [Exploring AI optimization](https://github.com/nebuly-ai/exploring-AI-optimization) to start getting into it. 



## Literature reviews and papers
Legend: 
- ✏️  100-499 citations, ✏️✏️ $\geq$ 500 citations
- ⭐  100-249 stars, ⭐⭐ $\geq$ 250 stars

Sorting: chronological/alphabetic order
<br> 

### Literature reviews

-title+link

### Papers
2022
- title xxx


2021
- - title xxx 

2020
- xxx

## Courses, webinars and blogs

Webinars, video content
- [xxxx

Blogs, written content
- xxxx link


<img height="25" width="100%" src="https://user-images.githubusercontent.com/83510798/171454644-d4b980bc-15ab-4a31-847c-75c36c5bd96b.png">

<p align="center">
  <a href="https://discord.gg/RbeQMu886J">Join the community</a> •
  <a href="https://github.com/nebuly-ai/learning-AI-optimization#contribute">Contribute to the library</a>
</p>
